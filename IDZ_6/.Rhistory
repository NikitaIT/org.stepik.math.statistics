}
# Теперь находим theta, максимизирующий logmul
mulest=maxNR(logmul, start=c(1,1))$estimate
# Значение второй статистики считается так:
chi_mlemul=chi(mulest)
# Вычисляем pvalue и записываем ответ
p.value_min=1-pchisq(minest$minimum,df)
p.value_mlemul=1-pchisq(chi_mlemul,df)
res=list(minest$minimum,minest$estimate[1],minest$estimate[2],p.value_min, chi_mlemul, mulest[1],mulest[2], p.value_mlemul)
names(res)=c("chi_minimum","min_theta_estimate_L","min_theta_estimate_R","p.value_min","chi_mlemul","mle_mul_theta_estimate_L","mle_mul_theta_estimate_R", "p.value_mlemul")
return(as.data.frame(t(res)))
}
rbind(check(sample = goftest$X1_cauchy,pFUN = pcauchy),
check(sample = goftest$X2_cauchy,pFUN = pcauchy),
check(sample = goftest$X3_cauchy,pFUN = pcauchy),
check(sample = goftest$X1_norm,pFUN = pnorm),
check(sample = goftest$X2_norm,pFUN = pnorm),
check(sample = goftest$X3_norm,pFUN = pnorm),
check(sample = goftest$X1_pois,pFUN = ppois))
check=function(sample,pFUN=pbeta,k=10,d=2){
df=k-d-1
n=length(sample)
br=seq(min(sample),max(sample),length.out=(k+1)) # Задаем разбиение носителя [0,1] равноотстоящими точками
obs=hist(sample,breaks=br,plot=F)$counts # Наблюдаемое число попаданий в интервалы
# Ожидаемо число (или вероятности попаданий в интервалы) --- теперь, является функцией от параметра theta
# Так и реализуем их:
prob=function(theta){
return (pFUN(br[2:(k+1)],theta[1],theta[2])-pFUN(br[1:k],theta[1],theta[2]))
}
# Статистика хи-квадрат выглядит так же, как и для простой гипотезы, только теперь это функция от theta.
chi=function(theta){
pb=prob(theta)
ch=obs-n*pb
ch=ch/sqrt(n*pb)
ch=ch^2
return(sum(ch))
}
nlm(chi,c(mean(sample),mean(sample)))
# Первый способ --- вычислить минимум по theta
minest=nlm(chi,mean(sample)) # делается это с помощью функции nlm
# Второй способ --- подставить вместо theta ОМП для мультиномиального распределения
logmul=function(theta){
pr=prob(theta)
lm=obs*log(pr) # Вычисляем логарифм функции правдоподобия мультиномиального распределения с точностью до постоянной,
# не зависящей от theta
return (lm)
}
# Теперь находим theta, максимизирующий logmul
mulest=maxNR(logmul, start=c(1,1))$estimate
# Значение второй статистики считается так:
chi_mlemul=chi(mulest)
# Вычисляем pvalue и записываем ответ
p.value_min=1-pchisq(minest$minimum,df)
p.value_mlemul=1-pchisq(chi_mlemul,df)
res=list(minest$minimum,minest$estimate[1],minest$estimate[2],p.value_min, chi_mlemul, mulest[1],mulest[2], p.value_mlemul)
names(res)=c("chi_minimum","min_theta_estimate_L","min_theta_estimate_R","p.value_min","chi_mlemul","mle_mul_theta_estimate_L","mle_mul_theta_estimate_R", "p.value_mlemul")
return(as.data.frame(t(res)))
}
res=check(x)
print(res)
check=function(sample,pFUN=pbeta,k=10,d=2){
df=k-d-1
n=length(sample)
br=seq(min(sample),max(sample),length.out=(k+1)) # Задаем разбиение носителя [0,1] равноотстоящими точками
obs=hist(sample,breaks=br,plot=F)$counts # Наблюдаемое число попаданий в интервалы
# Ожидаемо число (или вероятности попаданий в интервалы) --- теперь, является функцией от параметра theta
# Так и реализуем их:
prob=function(theta){
return (pFUN(br[2:(k+1)],theta[1],theta[2])-pFUN(br[1:k],theta[1],theta[2]))
}
# Статистика хи-квадрат выглядит так же, как и для простой гипотезы, только теперь это функция от theta.
chi=function(theta){
pb=prob(theta)
ch=obs-n*pb
ch=ch/sqrt(n*pb)
ch=ch^2
return(sum(ch))
}
nlm(chi,c(min(sample),min(sample)))
# Первый способ --- вычислить минимум по theta
minest=nlm(chi,mean(sample)) # делается это с помощью функции nlm
# Второй способ --- подставить вместо theta ОМП для мультиномиального распределения
logmul=function(theta){
pr=prob(theta)
lm=obs*log(pr) # Вычисляем логарифм функции правдоподобия мультиномиального распределения с точностью до постоянной,
# не зависящей от theta
return (lm)
}
# Теперь находим theta, максимизирующий logmul
mulest=maxNR(logmul, start=c(1,1))$estimate
# Значение второй статистики считается так:
chi_mlemul=chi(mulest)
# Вычисляем pvalue и записываем ответ
p.value_min=1-pchisq(minest$minimum,df)
p.value_mlemul=1-pchisq(chi_mlemul,df)
res=list(minest$minimum,minest$estimate[1],minest$estimate[2],p.value_min, chi_mlemul, mulest[1],mulest[2], p.value_mlemul)
names(res)=c("chi_minimum","min_theta_estimate_L","min_theta_estimate_R","p.value_min","chi_mlemul","mle_mul_theta_estimate_L","mle_mul_theta_estimate_R", "p.value_mlemul")
return(as.data.frame(t(res)))
}
x=rbeta(1000,2,5)
res=check(x)
print(res)
check=function(sample,pFUN=pbeta,k=10,d=2){
df=k-d-1
n=length(sample)
br=seq(min(sample),max(sample),length.out=(k+1)) # Задаем разбиение носителя [0,1] равноотстоящими точками
obs=hist(sample,breaks=br,plot=F)$counts # Наблюдаемое число попаданий в интервалы
# Ожидаемо число (или вероятности попаданий в интервалы) --- теперь, является функцией от параметра theta
# Так и реализуем их:
prob=function(theta){
return (pFUN(br[2:(k+1)],theta[1],theta[2])-pFUN(br[1:k],theta[1],theta[2]))
}
# Статистика хи-квадрат выглядит так же, как и для простой гипотезы, только теперь это функция от theta.
chi=function(theta){
pb=prob(theta)
ch=obs-n*pb
ch=ch/sqrt(n*pb)
ch=ch^2
return(sum(ch))
}
nlm(chi,c(1,1))
# Первый способ --- вычислить минимум по theta
minest=nlm(chi,mean(sample)) # делается это с помощью функции nlm
# Второй способ --- подставить вместо theta ОМП для мультиномиального распределения
logmul=function(theta){
pr=prob(theta)
lm=obs*log(pr) # Вычисляем логарифм функции правдоподобия мультиномиального распределения с точностью до постоянной,
# не зависящей от theta
return (lm)
}
# Теперь находим theta, максимизирующий logmul
mulest=maxNR(logmul, start=c(1,1))$estimate
# Значение второй статистики считается так:
chi_mlemul=chi(mulest)
# Вычисляем pvalue и записываем ответ
p.value_min=1-pchisq(minest$minimum,df)
p.value_mlemul=1-pchisq(chi_mlemul,df)
res=list(minest$minimum,minest$estimate[1],minest$estimate[2],p.value_min, chi_mlemul, mulest[1],mulest[2], p.value_mlemul)
names(res)=c("chi_minimum","min_theta_estimate_L","min_theta_estimate_R","p.value_min","chi_mlemul","mle_mul_theta_estimate_L","mle_mul_theta_estimate_R", "p.value_mlemul")
return(as.data.frame(t(res)))
}
x=rbeta(1000,2,5)
res=check(x)
print(res)
logmul=function(theta){
pr=prob(theta)
lm=obs*log(pr) # Вычисляем логарифм функции правдоподобия мультиномиального распределения с точностью до постоянной,
# не зависящей от theta
return (lm)
}
check=function(sample,pFUN=pbeta,k=10,d=2){
df=k-d-1
n=length(sample)
br=seq(min(sample),max(sample),length.out=(k+1)) # Задаем разбиение носителя [0,1] равноотстоящими точками
obs=hist(sample,breaks=br,plot=F)$counts # Наблюдаемое число попаданий в интервалы
# Ожидаемо число (или вероятности попаданий в интервалы) --- теперь, является функцией от параметра theta
# Так и реализуем их:
prob=function(theta){
return (pFUN(br[2:(k+1)],theta[1],theta[2])-pFUN(br[1:k],theta[1],theta[2]))
}
# Статистика хи-квадрат выглядит так же, как и для простой гипотезы, только теперь это функция от theta.
chi=function(theta){
pb=prob(theta)
ch=obs-n*pb
ch=ch/sqrt(n*pb)
ch=ch^2
return(sum(ch))
}
nlm(chi,c(1,1))
# Первый способ --- вычислить минимум по theta
minest=nlm(chi,c(1,1)) # делается это с помощью функции nlm
# Второй способ --- подставить вместо theta ОМП для мультиномиального распределения
logmul=function(theta){
pr=prob(theta)
lm=obs*log(pr) # Вычисляем логарифм функции правдоподобия мультиномиального распределения с точностью до постоянной,
# не зависящей от theta
return (lm)
}
# Теперь находим theta, максимизирующий logmul
mulest=maxNR(logmul, start=c(1,1))$estimate
# Значение второй статистики считается так:
chi_mlemul=chi(mulest)
# Вычисляем pvalue и записываем ответ
p.value_min=1-pchisq(minest$minimum,df)
p.value_mlemul=1-pchisq(chi_mlemul,df)
res=list(minest$minimum,minest$estimate[1],minest$estimate[2],p.value_min, chi_mlemul, mulest[1],mulest[2], p.value_mlemul)
names(res)=c("chi_minimum","min_theta_estimate_L","min_theta_estimate_R","p.value_min","chi_mlemul","mle_mul_theta_estimate_L","mle_mul_theta_estimate_R", "p.value_mlemul")
return(as.data.frame(t(res)))
}
res=check(x)
print(res)
rbind(check(sample = goftest$X1_cauchy,pFUN = pcauchy),
check(sample = goftest$X2_cauchy,pFUN = pcauchy),
check(sample = goftest$X3_cauchy,pFUN = pcauchy),
check(sample = goftest$X1_norm,pFUN = pnorm),
check(sample = goftest$X2_norm,pFUN = pnorm),
check(sample = goftest$X3_norm,pFUN = pnorm),
check(sample = goftest$X1_pois,pFUN = ppois))
check(sample = goftest$X1_pois,pFUN = ppois)
a = check(sample = goftest$X1_pois,pFUN = ppois)
a
a = check(sample = goftest$X1_pois,pFUN = ppois)
rbind(check(sample = goftest$X1_cauchy,pFUN = pcauchy),
check(sample = goftest$X2_cauchy,pFUN = pcauchy),
check(sample = goftest$X3_cauchy,pFUN = pcauchy),
check(sample = goftest$X1_norm,pFUN = pnorm),
check(sample = goftest$X2_norm,pFUN = pnorm),
check(sample = goftest$X3_norm,pFUN = pnorm)
)
res=check(x)
print(res)
rbind(check(sample = goftest$X1_cauchy,pFUN = pcauchy),
check(sample = goftest$X2_cauchy,pFUN = pcauchy),
check(sample = goftest$X3_cauchy,pFUN = pcauchy),
check(sample = goftest$X1_norm,pFUN = pnorm),
check(sample = goftest$X2_norm,pFUN = pnorm),
check(sample = goftest$X3_norm,pFUN = pnorm)
)
check(sample = goftest$X1_chisq,pFUN = pchisq)
check(sample = goftest$X1_chisq,pFUN = pchisq)
rbind(check(sample = goftest$X1_cauchy,pFUN = pcauchy),
check(sample = goftest$X2_cauchy,pFUN = pcauchy),
check(sample = goftest$X3_cauchy,pFUN = pcauchy),
check(sample = goftest$X1_norm,pFUN = pnorm),
check(sample = goftest$X2_norm,pFUN = pnorm),
check(sample = goftest$X3_norm,pFUN = pnorm),
check(sample = goftest$X1_chisq,pFUN = pchisq)
)
check(sample = goftest$X1_chisq,pFUN = pchisq)
check(sample = goftest$X1_chisq,pFUN = pchisq)
goftest$X1_chisq
pchisq
ppois
pcauchy
pnorm
pchisq
ppois
rbind(check(sample = goftest$X1_cauchy,pFUN = pcauchy),
check(sample = goftest$X2_cauchy,pFUN = pcauchy),
check(sample = goftest$X3_cauchy,pFUN = pcauchy),
check(sample = goftest$X1_norm,pFUN = pnorm),
check(sample = goftest$X2_norm,pFUN = pnorm),
check(sample = goftest$X3_norm,pFUN = pnorm),
check(sample = goftest$X1_chisq,pFUN = pgamma)
)
check(sample = goftest$X1_chisq,pFUN = pgamma)
rbind(check(sample = goftest$X1_cauchy,pFUN = pcauchy),
check(sample = goftest$X2_cauchy,pFUN = pcauchy),
check(sample = goftest$X3_cauchy,pFUN = pcauchy),
check(sample = goftest$X1_norm,pFUN = pnorm),
check(sample = goftest$X2_norm,pFUN = pnorm),
check(sample = goftest$X3_norm,pFUN = pnorm),
check(sample = goftest$X1_chisq,pFUN = pgamma),
check(sample = goftest$X2_chisq,pFUN = pgamma),
check(sample = goftest$X3_chisq,pFUN = pgamma)
)
check(sample = goftest$X1_nbinom_m.10,pFUN = pnbinom)
pnbinom
rbind(check(sample = goftest$X1_cauchy,pFUN = pcauchy),
check(sample = goftest$X2_cauchy,pFUN = pcauchy),
check(sample = goftest$X3_cauchy,pFUN = pcauchy),
check(sample = goftest$X1_norm,pFUN = pnorm),
check(sample = goftest$X2_norm,pFUN = pnorm),
check(sample = goftest$X3_norm,pFUN = pnorm),
check(sample = goftest$X1_chisq,pFUN = pgamma),
check(sample = goftest$X2_chisq,pFUN = pgamma),
check(sample = goftest$X3_chisq,pFUN = pgamma)
)
check(sample = goftest$X1_nbinom_m.10,pFUN = pnbinom)
rbind(check(sample = goftest$X1_cauchy,pFUN = pcauchy),
check(sample = goftest$X2_cauchy,pFUN = pcauchy),
check(sample = goftest$X3_cauchy,pFUN = pcauchy),
check(sample = goftest$X1_norm,pFUN = pnorm),
check(sample = goftest$X2_norm,pFUN = pnorm),
check(sample = goftest$X3_norm,pFUN = pnorm),
check(sample = goftest$X1_chisq,pFUN = pgamma),
check(sample = goftest$X2_chisq,pFUN = pgamma),
check(sample = goftest$X3_chisq,pFUN = pgamma)
)
check(sample = goftest$X1_chisq,pFUN = pchisq)
t <- rexp(100, 2)
t
loglik <- function(theta) sum(log(theta) - theta*t)
loglik
check=function(sample,pFUN=pbeta,k=10,d=2){
df=k-d-1
n=length(sample)
br=seq(min(sample),max(sample),length.out=(k+1)) # Задаем разбиение носителя [0,1] равноотстоящими точками
obs=hist(sample,breaks=br,plot=F)$counts # Наблюдаемое число попаданий в интервалы
# Ожидаемо число (или вероятности попаданий в интервалы) --- теперь, является функцией от параметра theta
# Так и реализуем их:
prob=function(theta){
return (pFUN(br[2:(k+1)],theta[1],theta[2])-pFUN(br[1:k],theta[1],theta[2]))
}
# Статистика хи-квадрат выглядит так же, как и для простой гипотезы, только теперь это функция от theta.
chi=function(theta){
pb=prob(theta)
ch=obs-n*pb
ch=ch/sqrt(n*pb)
ch=ch^2
return(sum(ch))
}
nlm(chi,c(1,1))
# Первый способ --- вычислить минимум по theta
minest=nlm(chi,c(1,1)) # делается это с помощью функции nlm
# Второй способ --- подставить вместо theta ОМП для мультиномиального распределения
logmul=function(theta){
lm=obs*log(prob(theta)) # Вычисляем логарифм функции правдоподобия мультиномиального распределения с точностью до постоянной,
# не зависящей от theta
return (lm)
}
t <- rexp(100, 2)
loglik <- function(theta) sum(log(theta) - theta*t)
## Note the log-likelihood and gradient are summed over observations
gradlik <- function(theta) sum(1/theta - t)
hesslik <- function(theta) -100/theta^2
# Теперь находим theta, максимизирующий logmul
mulest=maxNR(logmul, start=c(1,1),grad = gradlik)$estimate
# Значение второй статистики считается так:
chi_mlemul=chi(mulest)
# Вычисляем pvalue и записываем ответ
p.value_min=1-pchisq(minest$minimum,df)
p.value_mlemul=1-pchisq(chi_mlemul,df)
res=list(minest$minimum,minest$estimate[1],minest$estimate[2],p.value_min, chi_mlemul, mulest[1],mulest[2], p.value_mlemul)
names(res)=c("chi_minimum","min_theta_estimate_L","min_theta_estimate_R","p.value_min","chi_mlemul","mle_mul_theta_estimate_L","mle_mul_theta_estimate_R", "p.value_mlemul")
return(as.data.frame(t(res)))
}
res=check(x)
res=check(x)
check=function(sample,pFUN=pbeta,k=10,d=2){
df=k-d-1
n=length(sample)
br=seq(min(sample),max(sample),length.out=(k+1)) # Задаем разбиение носителя [0,1] равноотстоящими точками
obs=hist(sample,breaks=br,plot=F)$counts # Наблюдаемое число попаданий в интервалы
# Ожидаемо число (или вероятности попаданий в интервалы) --- теперь, является функцией от параметра theta
# Так и реализуем их:
prob=function(theta){
return (pFUN(br[2:(k+1)],theta[1],theta[2])-pFUN(br[1:k],theta[1],theta[2]))
}
# Статистика хи-квадрат выглядит так же, как и для простой гипотезы, только теперь это функция от theta.
chi=function(theta){
pb=prob(theta)
ch=obs-n*pb
ch=ch/sqrt(n*pb)
ch=ch^2
return(sum(ch))
}
nlm(chi,c(1,1))
# Первый способ --- вычислить минимум по theta
minest=nlm(chi,c(1,1)) # делается это с помощью функции nlm
# Второй способ --- подставить вместо theta ОМП для мультиномиального распределения
logmul=function(theta){
lm=obs*log(prob(theta)) # Вычисляем логарифм функции правдоподобия мультиномиального распределения с точностью до постоянной,
# не зависящей от theta
return (lm)
}
t <- rexp(100, 2)
loglik <- function(theta) sum(log(theta) - theta*t)
## Note the log-likelihood and gradient are summed over observations
gradlik <- function(theta) sum(1/theta - t)
hesslik <- function(theta) -100/theta^2
# Теперь находим theta, максимизирующий logmul
mulest=maxNR(logmul, start=c(1,1))$estimate
# Значение второй статистики считается так:
chi_mlemul=chi(mulest)
# Вычисляем pvalue и записываем ответ
p.value_min=1-pchisq(minest$minimum,df)
p.value_mlemul=1-pchisq(chi_mlemul,df)
res=list(minest$minimum,minest$estimate[1],minest$estimate[2],p.value_min, chi_mlemul, mulest[1],mulest[2], p.value_mlemul)
names(res)=c("chi_minimum","min_theta_estimate_L","min_theta_estimate_R","p.value_min","chi_mlemul","mle_mul_theta_estimate_L","mle_mul_theta_estimate_R", "p.value_mlemul")
return(as.data.frame(t(res)))
}
res=check(x)
print(res)
check=function(sample,pFUN=pbeta,k=10,d=2){
df=k-d-1
n=length(sample)
br=seq(min(sample),max(sample),length.out=(k+1)) # Задаем разбиение носителя [0,1] равноотстоящими точками
obs=hist(sample,breaks=br,plot=F)$counts # Наблюдаемое число попаданий в интервалы
# Ожидаемо число (или вероятности попаданий в интервалы) --- теперь, является функцией от параметра theta
# Так и реализуем их:
prob=function(theta){
return (pFUN(br[2:(k+1)],theta[1],theta[2])-pFUN(br[1:k],theta[1],theta[2]))
}
# Статистика хи-квадрат выглядит так же, как и для простой гипотезы, только теперь это функция от theta.
chi=function(theta){
pb=prob(theta)
ch=obs-n*pb
ch=ch/sqrt(n*pb)
ch=ch^2
return(sum(ch))
}
nlm(chi,c(1,1))
# Первый способ --- вычислить минимум по theta
minest=nlm(chi,c(1,1)) # делается это с помощью функции nlm
# Второй способ --- подставить вместо theta ОМП для мультиномиального распределения
logmul=function(theta){
lm=obs*log(prob(theta)) # Вычисляем логарифм функции правдоподобия мультиномиального распределения с точностью до постоянной,
# не зависящей от theta
return (lm)
}
t <- rexp(100, 2)
loglik <- function(theta) sum(log(theta) - theta*t)
## Note the log-likelihood and gradient are summed over observations
gradlik <- function(theta) sum(1/theta - t)
hesslik <- function(theta) -100/theta^2
# Теперь находим theta, максимизирующий logmul
mulest=maxNR(logmul, start=c(1,1),gradlik)$estimate
# Значение второй статистики считается так:
chi_mlemul=chi(mulest)
# Вычисляем pvalue и записываем ответ
p.value_min=1-pchisq(minest$minimum,df)
p.value_mlemul=1-pchisq(chi_mlemul,df)
res=list(minest$minimum,minest$estimate[1],minest$estimate[2],p.value_min, chi_mlemul, mulest[1],mulest[2], p.value_mlemul)
names(res)=c("chi_minimum","min_theta_estimate_L","min_theta_estimate_R","p.value_min","chi_mlemul","mle_mul_theta_estimate_L","mle_mul_theta_estimate_R", "p.value_mlemul")
return(as.data.frame(t(res)))
}
check(sample = goftest$X1_chisq,pFUN = pchisq)
check(sample = goftest$X1_nbinom_m.10,pFUN = pnbinom)
check=function(sample,pFUN=pbeta,k=10,d=2){
df=k-d-1
n=length(sample)
br=seq(min(sample),max(sample),length.out=(k+1)) # Задаем разбиение носителя [0,1] равноотстоящими точками
obs=hist(sample,breaks=br,plot=F)$counts # Наблюдаемое число попаданий в интервалы
# Ожидаемо число (или вероятности попаданий в интервалы) --- теперь, является функцией от параметра theta
# Так и реализуем их:
prob=function(theta){
return (pFUN(br[2:(k+1)],theta[1],theta[2])-pFUN(br[1:k],theta[1],theta[2]))
}
# Статистика хи-квадрат выглядит так же, как и для простой гипотезы, только теперь это функция от theta.
chi=function(theta){
pb=prob(theta)
ch=obs-n*pb
ch=ch/sqrt(n*pb)
ch=ch^2
return(sum(ch))
}
nlm(chi,c(1,1))
# Первый способ --- вычислить минимум по theta
minest=nlm(chi,c(1,1)) # делается это с помощью функции nlm
# Второй способ --- подставить вместо theta ОМП для мультиномиального распределения
logmul=function(theta){
lm=obs*log(prob(theta)) # Вычисляем логарифм функции правдоподобия мультиномиального распределения с точностью до постоянной,
# не зависящей от theta
return (lm)
}
# Теперь находим theta, максимизирующий logmul
mulest=maxNR(logmul, start=c(1))$estimate
# Значение второй статистики считается так:
chi_mlemul=chi(mulest)
# Вычисляем pvalue и записываем ответ
p.value_min=1-pchisq(minest$minimum,df)
p.value_mlemul=1-pchisq(chi_mlemul,df)
res=list(minest$minimum,minest$estimate[1],minest$estimate[2],p.value_min, chi_mlemul, mulest[1],mulest[2], p.value_mlemul)
names(res)=c("chi_minimum","min_theta_estimate_L","min_theta_estimate_R","p.value_min","chi_mlemul","mle_mul_theta_estimate_L","mle_mul_theta_estimate_R", "p.value_mlemul")
return(as.data.frame(t(res)))
}
res=check(x)
x=rbeta(1000,2,5)
res=check(x)
check=function(sample,pFUN=pbeta,k=10,d=2){
df=k-d-1
n=length(sample)
br=seq(min(sample),max(sample),length.out=(k+1)) # Задаем разбиение носителя [0,1] равноотстоящими точками
obs=hist(sample,breaks=br,plot=F)$counts # Наблюдаемое число попаданий в интервалы
# Ожидаемо число (или вероятности попаданий в интервалы) --- теперь, является функцией от параметра theta
# Так и реализуем их:
prob=function(theta){
return (pFUN(br[2:(k+1)],theta[1],theta[2])-pFUN(br[1:k],theta[1],theta[2]))
}
# Статистика хи-квадрат выглядит так же, как и для простой гипотезы, только теперь это функция от theta.
chi=function(theta){
pb=prob(theta)
ch=obs-n*pb
ch=ch/sqrt(n*pb)
ch=ch^2
return(sum(ch))
}
nlm(chi,c(1,1))
# Первый способ --- вычислить минимум по theta
minest=nlm(chi,c(1,1)) # делается это с помощью функции nlm
# Второй способ --- подставить вместо theta ОМП для мультиномиального распределения
logmul=function(theta){
lm=obs*log(prob(theta)) # Вычисляем логарифм функции правдоподобия мультиномиального распределения с точностью до постоянной,
# не зависящей от theta
return (lm)
}
# Теперь находим theta, максимизирующий logmul
mulest=maxNR(logmul, start=c(1,1))$estimate
# Значение второй статистики считается так:
chi_mlemul=chi(mulest)
# Вычисляем pvalue и записываем ответ
p.value_min=1-pchisq(minest$minimum,df)
p.value_mlemul=1-pchisq(chi_mlemul,df)
res=list(minest$minimum,minest$estimate[1],minest$estimate[2],p.value_min, chi_mlemul, mulest[1],mulest[2], p.value_mlemul)
names(res)=c("chi_minimum","min_theta_estimate_L","min_theta_estimate_R","p.value_min","chi_mlemul","mle_mul_theta_estimate_L","mle_mul_theta_estimate_R", "p.value_mlemul")
return(as.data.frame(t(res)))
}
res=check(x)
print(res)
rbind(check(sample = goftest$X1_cauchy,pFUN = pcauchy),
check(sample = goftest$X2_cauchy,pFUN = pcauchy),
check(sample = goftest$X3_cauchy,pFUN = pcauchy),
check(sample = goftest$X1_norm,pFUN = pnorm),
check(sample = goftest$X2_norm,pFUN = pnorm),
check(sample = goftest$X3_norm,pFUN = pnorm),
check(sample = goftest$X1_chisq,pFUN = pgamma),
check(sample = goftest$X2_chisq,pFUN = pgamma),
check(sample = goftest$X3_chisq,pFUN = pgamma)
)
check(sample = goftest$X1_chisq,pFUN = pchisq)
check(sample = goftest$X1_nbinom_m.10,pFUN = pnbinom)
